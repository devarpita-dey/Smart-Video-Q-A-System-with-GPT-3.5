{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-Pj8zDMXL2j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_uCMSeJXW1O",
        "outputId": "5ee5105a-6630-48cb-8534-1f5e783b2d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.4.26)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube_transcript_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-4bRdn-XW4Q"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaAN6TFuXW7E"
      },
      "outputs": [],
      "source": [
        "def get_video_id(url_link):\n",
        "  return url_link.split(\"watch?v=\")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4u3usaFiXW9u",
        "outputId": "e85406ac-5d7e-497c-fbcf-df5afba51e74"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xDQL3vWwcp0&list=PL49M3zg4eCviRD4-hTjS5aUZs3PzAFYkJ'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_video_id(\"https://www.youtube.com/watch?v=xDQL3vWwcp0&list=PL49M3zg4eCviRD4-hTjS5aUZs3PzAFYkJ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f817bHuRXXCS"
      },
      "outputs": [],
      "source": [
        "transcript= YouTubeTranscriptApi.get_transcript(get_video_id(\"https://www.youtube.com/watch?v=xDQL3vWwcp0&list=PL49M3zg4eCviRD4-hTjS5aUZs3PzAFYkJ\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21W6nfvcXXE9",
        "outputId": "f393bb7c-bfca-48a9-edde-3380d936b7db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': \"hello everyone I am Santi and I'm\",\n",
              "  'start': 0.16,\n",
              "  'duration': 3.559},\n",
              " {'text': 'currently working as an ml engineer',\n",
              "  'start': 1.839,\n",
              "  'duration': 3.48},\n",
              " {'text': 'today we are going to do an awesome',\n",
              "  'start': 3.719,\n",
              "  'duration': 3.241},\n",
              " {'text': 'machine learning project that you can',\n",
              "  'start': 5.319,\n",
              "  'duration': 4.44},\n",
              " {'text': 'add to your resume and impress all the',\n",
              "  'start': 6.96,\n",
              "  'duration': 4.92},\n",
              " {'text': \"interviewers um I'm dedicated to\",\n",
              "  'start': 9.759,\n",
              "  'duration': 4.201},\n",
              " {'text': 'teaching machine learning to all of you',\n",
              "  'start': 11.88,\n",
              "  'duration': 4.36},\n",
              " {'text': 'and to ensure that you all learned an ml',\n",
              "  'start': 13.96,\n",
              "  'duration': 5.319},\n",
              " {'text': 'job as soon as possible okay so without',\n",
              "  'start': 16.24,\n",
              "  'duration': 5.32},\n",
              " {'text': \"any further Ado let's Dive Right\",\n",
              "  'start': 19.279,\n",
              "  'duration': 6.641},\n",
              " {'text': 'In so our title is going to be um so our',\n",
              "  'start': 21.56,\n",
              "  'duration': 6.479},\n",
              " {'text': 'project title is going to be uh YouTube',\n",
              "  'start': 25.92,\n",
              "  'duration': 4.88},\n",
              " {'text': 'video summarizer with llm', 'start': 28.039, 'duration': 4.641},\n",
              " {'text': \"well so what's going to do is going to\",\n",
              "  'start': 30.8,\n",
              "  'duration': 4.04},\n",
              " {'text': 'take in a video and you can ask any',\n",
              "  'start': 32.68,\n",
              "  'duration': 4.0},\n",
              " {'text': 'question regarding the videos contents',\n",
              "  'start': 34.84,\n",
              "  'duration': 4.64},\n",
              " {'text': \"the images Etc and that's going to be\",\n",
              "  'start': 36.68,\n",
              "  'duration': 5.199},\n",
              " {'text': 'really really good really useful as well',\n",
              "  'start': 39.48,\n",
              "  'duration': 4.12},\n",
              " {'text': 'and that can be a mini deployed project',\n",
              "  'start': 41.879,\n",
              "  'duration': 5.561},\n",
              " {'text': 'as well okay so first things first um',\n",
              "  'start': 43.6,\n",
              "  'duration': 5.92},\n",
              " {'text': \"let's let's let's think about why do we\",\n",
              "  'start': 47.44,\n",
              "  'duration': 3.36},\n",
              " {'text': 'need this in the first place the', 'start': 49.52, 'duration': 3.0},\n",
              " {'text': 'interviewer might say why not just use',\n",
              "  'start': 50.8,\n",
              "  'duration': 4.64},\n",
              " {'text': 'chat GPT right because chat gpg has now',\n",
              "  'start': 52.52,\n",
              "  'duration': 4.76},\n",
              " {'text': 'enabled the search web feature for every',\n",
              "  'start': 55.44,\n",
              "  'duration': 3.799},\n",
              " {'text': 'free user right so you might be', 'start': 57.28, 'duration': 4.32},\n",
              " {'text': 'wondering why not just use that okay so',\n",
              "  'start': 59.239,\n",
              "  'duration': 3.921},\n",
              " {'text': \"let's see why we are not going to use\",\n",
              "  'start': 61.6,\n",
              "  'duration': 3.72},\n",
              " {'text': 'that as you can see right here we have',\n",
              "  'start': 63.16,\n",
              "  'duration': 6.12},\n",
              " {'text': \"our chat GPT open and let's see um which\",\n",
              "  'start': 65.32,\n",
              "  'duration': 6.439},\n",
              " {'text': 'video are we going to use yeah so this',\n",
              "  'start': 69.28,\n",
              "  'duration': 4.12},\n",
              " {'text': 'is a video that we are going to use',\n",
              "  'start': 71.759,\n",
              "  'duration': 3.761},\n",
              " {'text': 'right here as you can see my binary',\n",
              "  'start': 73.4,\n",
              "  'duration': 4.2},\n",
              " {'text': 'classification video which is of the',\n",
              "  'start': 75.52,\n",
              "  'duration': 6.08},\n",
              " {'text': \"length of 32 32 minutes okay so let's\",\n",
              "  'start': 77.6,\n",
              "  'duration': 6.36},\n",
              " {'text': 'put this inside the chat GPD and I will',\n",
              "  'start': 81.6,\n",
              "  'duration': 6.28},\n",
              " {'text': 'the search web feature and say write',\n",
              "  'start': 83.96,\n",
              "  'duration': 7.96},\n",
              " {'text': 'the transcript for this', 'start': 87.88, 'duration': 4.04},\n",
              " {'text': 'this for this video because first of all',\n",
              "  'start': 94.92,\n",
              "  'duration': 5.0},\n",
              " {'text': \"we'll need the transcript\", 'start': 97.88, 'duration': 4.559},\n",
              " {'text': 'right as you can see right', 'start': 99.92, 'duration': 5.32},\n",
              " {'text': \"here it says that it's unable to\",\n",
              "  'start': 102.439,\n",
              "  'duration': 5.521},\n",
              " {'text': 'actually get the video um transcript so',\n",
              "  'start': 105.24,\n",
              "  'duration': 3.919},\n",
              " {'text': \"if you don't have the transcript\",\n",
              "  'start': 107.96,\n",
              "  'duration': 2.6},\n",
              " {'text': \"obviously then you won't be able to do\",\n",
              "  'start': 109.159,\n",
              "  'duration': 3.481},\n",
              " {'text': 'anything with it right okay whenever you',\n",
              "  'start': 110.56,\n",
              "  'duration': 4.159},\n",
              " {'text': \"get any project it's very important to\",\n",
              "  'start': 112.64,\n",
              "  'duration': 3.519},\n",
              " {'text': 'understand that you first need to break',\n",
              "  'start': 114.719,\n",
              "  'duration': 3.601},\n",
              " {'text': 'the project down into smaller pieces',\n",
              "  'start': 116.159,\n",
              "  'duration': 4.0},\n",
              " {'text': 'that you can tackle easily this is very',\n",
              "  'start': 118.32,\n",
              "  'duration': 3.6},\n",
              " {'text': 'important because if you think that how',\n",
              "  'start': 120.159,\n",
              "  'duration': 3.481},\n",
              " {'text': \"how am I going to do that we don't have\",\n",
              "  'start': 121.92,\n",
              "  'duration': 3.799},\n",
              " {'text': \"this we don't have that at the first so\",\n",
              "  'start': 123.64,\n",
              "  'duration': 4.24},\n",
              " {'text': \"this going to be very confusing so let's\",\n",
              "  'start': 125.719,\n",
              "  'duration': 4.281},\n",
              " {'text': 'tackle it one by one step by step',\n",
              "  'start': 127.88,\n",
              "  'duration': 3.56},\n",
              " {'text': 'remember this for any project that you',\n",
              "  'start': 130.0,\n",
              "  'duration': 3.2},\n",
              " {'text': \"are going to do okay I'm going to use\",\n",
              "  'start': 131.44,\n",
              "  'duration': 4.2},\n",
              " {'text': 'Google collab here because we need GPU',\n",
              "  'start': 133.2,\n",
              "  'duration': 4.2},\n",
              " {'text': \"for our support so if you don't have GPU\",\n",
              "  'start': 135.64,\n",
              "  'duration': 3.2},\n",
              " {'text': \"on your system or you're using any\",\n",
              "  'start': 137.4,\n",
              "  'duration': 3.68},\n",
              " {'text': \"Windows system you're using a Mac system\",\n",
              "  'start': 138.84,\n",
              "  'duration': 3.84},\n",
              " {'text': \"whatever it is it doesn't matter as long\",\n",
              "  'start': 141.08,\n",
              "  'duration': 3.239},\n",
              " {'text': 'as you have Google collab you can just',\n",
              "  'start': 142.68,\n",
              "  'duration': 3.919},\n",
              " {'text': \"go in it's free for you to use and you\",\n",
              "  'start': 144.319,\n",
              "  'duration': 4.441},\n",
              " {'text': 'can do the project here and in your',\n",
              "  'start': 146.599,\n",
              "  'duration': 3.761},\n",
              " {'text': 'resume you can just put in', 'start': 148.76, 'duration': 5.36},\n",
              " {'text': \"link okay so let's do first install\",\n",
              "  'start': 150.36,\n",
              "  'duration': 5.12},\n",
              " {'text': \"let's first install the YouTube\",\n",
              "  'start': 154.12,\n",
              "  'duration': 3.32},\n",
              " {'text': 'transcript', 'start': 155.48, 'duration': 4.64},\n",
              " {'text': 'API great now we have the YouTube trans',\n",
              "  'start': 157.44,\n",
              "  'duration': 5.0},\n",
              " {'text': 'transcript API so now what we going to',\n",
              "  'start': 160.12,\n",
              "  'duration': 4.08},\n",
              " {'text': 'do is basically get the link provide the',\n",
              "  'start': 162.44,\n",
              "  'duration': 4.96},\n",
              " {'text': 'link to the video um to this library and',\n",
              "  'start': 164.2,\n",
              "  'duration': 5.399},\n",
              " {'text': 'generate the transcript using', 'start': 167.4, 'duration': 4.24},\n",
              " {'text': \"this now we're going to import the\",\n",
              "  'start': 169.599,\n",
              "  'duration': 3.521},\n",
              " {'text': 'YouTube transcript', 'start': 171.64, 'duration': 4.36},\n",
              " {'text': 'API so', 'start': 173.12, 'duration': 6.88},\n",
              " {'text': 'from YouTube', 'start': 176.0, 'duration': 4.0},\n",
              " {'text': 'YouTube transcript API sounds good now',\n",
              "  'start': 182.92,\n",
              "  'duration': 6.92},\n",
              " {'text': \"let's get the video ID from the um video\",\n",
              "  'start': 186.599,\n",
              "  'duration': 5.0},\n",
              " {'text': 'so what we going to do is basically as',\n",
              "  'start': 189.84,\n",
              "  'duration': 3.44},\n",
              " {'text': 'you know this is the video right here',\n",
              "  'start': 191.599,\n",
              "  'duration': 3.801},\n",
              " {'text': 'and this is the video ID so whenever you',\n",
              "  'start': 193.28,\n",
              "  'duration': 3.64},\n",
              " {'text': \"put in a link you're going to get the\",\n",
              "  'start': 195.4,\n",
              "  'duration': 4.28},\n",
              " {'text': 'video ID from here get video ID is going',\n",
              "  'start': 196.92,\n",
              "  'duration': 4.76},\n",
              " {'text': 'to be this function great you now have',\n",
              "  'start': 199.68,\n",
              "  'duration': 4.68},\n",
              " {'text': \"the video ID so let's see what the video\",\n",
              "  'start': 201.68,\n",
              "  'duration': 4.44},\n",
              " {'text': 'ID looks', 'start': 204.36, 'duration': 4.079},\n",
              " {'text': 'like', 'start': 206.12, 'duration': 5.64},\n",
              " {'text': 'um copy', 'start': 208.439, 'duration': 3.321},\n",
              " {'text': 'this yeah this is the video ID yeah next',\n",
              "  'start': 212.799,\n",
              "  'duration': 4.681},\n",
              " {'text': 'thing is getting the transcript so',\n",
              "  'start': 215.84,\n",
              "  'duration': 4.08},\n",
              " {'text': 'basically get video ID we already have',\n",
              "  'start': 217.48,\n",
              "  'duration': 5.2},\n",
              " {'text': \"that so let's just store it in a\",\n",
              "  'start': 219.92,\n",
              "  'duration': 8.56},\n",
              " {'text': 'variable this one going to be video',\n",
              "  'start': 222.68,\n",
              "  'duration': 5.8},\n",
              " {'text': 'ID um', 'start': 229.959, 'duration': 5.761},\n",
              " {'text': \"yeah sounds good now let's see what the\",\n",
              "  'start': 232.4,\n",
              "  'duration': 7.08},\n",
              " {'text': 'transcript looks like', 'start': 235.72, 'duration': 3.76},\n",
              " {'text': 'yeah as you can see this is what the',\n",
              "  'start': 240.92,\n",
              "  'duration': 3.159},\n",
              " {'text': \"transcript looks like so now what you're\",\n",
              "  'start': 242.319,\n",
              "  'duration': 2.881},\n",
              " {'text': 'going to do', 'start': 244.079, 'duration': 3.841},\n",
              " {'text': 'is uh add all this', 'start': 245.2, 'duration': 5.72},\n",
              " {'text': 'together yep yeah so now what we going',\n",
              "  'start': 247.92,\n",
              "  'duration': 5.679},\n",
              " {'text': 'to do is do the transcript join so what',\n",
              "  'start': 250.92,\n",
              "  'duration': 5.36},\n",
              " {'text': 'does it going to look', 'start': 253.599, 'duration': 5.561},\n",
              " {'text': 'like exactly just join this together all',\n",
              "  'start': 256.28,\n",
              "  'duration': 5.72},\n",
              " {'text': 'the text features that you have in this',\n",
              "  'start': 259.16,\n",
              "  'duration': 5.36},\n",
              " {'text': 'transcript great now we can see what the',\n",
              "  'start': 262.0,\n",
              "  'duration': 6.639},\n",
              " {'text': 'transcript joint looks like', 'start': 264.52, 'duration': 4.119},\n",
              " {'text': 'yeah great as you can see right here',\n",
              "  'start': 270.32,\n",
              "  'duration': 6.68},\n",
              " {'text': 'this is our transcript that we', 'start': 273.6, 'duration': 7.56},\n",
              " {'text': 'have um okay as you can see we have it',\n",
              "  'start': 277.0,\n",
              "  'duration': 6.759},\n",
              " {'text': \"Santi but we can't do anything about it\",\n",
              "  'start': 281.16,\n",
              "  'duration': 5.319},\n",
              " {'text': \"so let's just forget about it for the\",\n",
              "  'start': 283.759,\n",
              "  'duration': 4.561},\n",
              " {'text': 'moment', 'start': 286.479, 'duration': 5.361},\n",
              " {'text': 'yeah um sounds good now what we going to',\n",
              "  'start': 288.32,\n",
              "  'duration': 5.04},\n",
              " {'text': 'do is basically we need to as you can',\n",
              "  'start': 291.84,\n",
              "  'duration': 4.799},\n",
              " {'text': 'see the transcript that you saw um it',\n",
              "  'start': 293.36,\n",
              "  'duration': 5.279},\n",
              " {'text': 'does not actually have a proper',\n",
              "  'start': 296.639,\n",
              "  'duration': 3.521},\n",
              " {'text': 'punctuation so we going to put in the',\n",
              "  'start': 298.639,\n",
              "  'duration': 3.641},\n",
              " {'text': \"punctuation now how we're going to do\",\n",
              "  'start': 300.16,\n",
              "  'duration': 4.759},\n",
              " {'text': \"that we're going to use a model for that\",\n",
              "  'start': 302.28,\n",
              "  'duration': 4.04},\n",
              " {'text': 'this is where the llm comes into the',\n",
              "  'start': 304.919,\n",
              "  'duration': 3.361},\n",
              " {'text': 'play okay so now as you can see like uh',\n",
              "  'start': 306.32,\n",
              "  'duration': 3.8},\n",
              " {'text': 'restoring the punctuation this is called',\n",
              "  'start': 308.28,\n",
              "  'duration': 4.199},\n",
              " {'text': 'a library which we have actually and',\n",
              "  'start': 310.12,\n",
              "  'duration': 4.44},\n",
              " {'text': 'this is actually a restore Punk Library',\n",
              "  'start': 312.479,\n",
              "  'duration': 3.72},\n",
              " {'text': 'yeah this is our Punk library that we',\n",
              "  'start': 314.56,\n",
              "  'duration': 3.72},\n",
              " {'text': \"have actually but there's a problem out\",\n",
              "  'start': 316.199,\n",
              "  'duration': 4.28},\n",
              " {'text': 'here the versions are very like old',\n",
              "  'start': 318.28,\n",
              "  'duration': 3.759},\n",
              " {'text': \"because it's three years ago so that is\",\n",
              "  'start': 320.479,\n",
              "  'duration': 3.641},\n",
              " {'text': \"why there's a patch for the Same by\",\n",
              "  'start': 322.039,\n",
              "  'duration': 4.561},\n",
              " {'text': 'another uh GitHub user so that that is',\n",
              "  'start': 324.12,\n",
              "  'duration': 4.919},\n",
              " {'text': 'what we are going to use here great so',\n",
              "  'start': 326.6,\n",
              "  'duration': 4.039},\n",
              " {'text': 'this is actually the thing please note',\n",
              "  'start': 329.039,\n",
              "  'duration': 3.201},\n",
              " {'text': \"it down because you're going to need\",\n",
              "  'start': 330.639,\n",
              "  'duration': 3.881},\n",
              " {'text': \"this if you use the normal ARB it's not\",\n",
              "  'start': 332.24,\n",
              "  'duration': 4.519},\n",
              " {'text': 'going to help great now the next thing',\n",
              "  'start': 334.52,\n",
              "  'duration': 4.6},\n",
              " {'text': 'comes is restoring the punctuations so',\n",
              "  'start': 336.759,\n",
              "  'duration': 3.801},\n",
              " {'text': 'from the r pun we going to import',\n",
              "  'start': 339.12,\n",
              "  'duration': 2.96},\n",
              " {'text': \"restore puns and then you're going to\",\n",
              "  'start': 340.56,\n",
              "  'duration': 3.88},\n",
              " {'text': 'use this restore Punk function so what',\n",
              "  'start': 342.08,\n",
              "  'duration': 4.28},\n",
              " {'text': 'this actually does behind the scenes is',\n",
              "  'start': 344.44,\n",
              "  'duration': 4.52},\n",
              " {'text': 'it uses a model from the hugging face',\n",
              "  'start': 346.36,\n",
              "  'duration': 4.679},\n",
              " {'text': 'library and this model is actually',\n",
              "  'start': 348.96,\n",
              "  'duration': 4.32},\n",
              " {'text': 'loaded here and this model is actually',\n",
              "  'start': 351.039,\n",
              "  'duration': 5.961},\n",
              " {'text': 'pre-trained for taking in bunch of text',\n",
              "  'start': 353.28,\n",
              "  'duration': 6.72},\n",
              " {'text': 'and then um getting the punctu ation',\n",
              "  'start': 357.0,\n",
              "  'duration': 5.36},\n",
              " {'text': 'back to that text great now that this is',\n",
              "  'start': 360.0,\n",
              "  'duration': 5.12},\n",
              " {'text': \"done let's move on to the um getting the\",\n",
              "  'start': 362.36,\n",
              "  'duration': 5.16},\n",
              " {'text': 'results from the punctuation so as you',\n",
              "  'start': 365.12,\n",
              "  'duration': 4.44},\n",
              " {'text': 'can see right here this one py toch',\n",
              "  'start': 367.52,\n",
              "  'duration': 5.2},\n",
              " {'text': 'model this model actually got loaded so',\n",
              "  'start': 369.56,\n",
              "  'duration': 4.759},\n",
              " {'text': 'one thing if you facing some problem',\n",
              "  'start': 372.72,\n",
              "  'duration': 4.36},\n",
              " {'text': \"with GPU it's very important to use this\",\n",
              "  'start': 374.319,\n",
              "  'duration': 6.521},\n",
              " {'text': 'actually um here yeah as you can see',\n",
              "  'start': 377.08,\n",
              "  'duration': 6.8},\n",
              " {'text': 'right here we have GPU enable T4 so you',\n",
              "  'start': 380.84,\n",
              "  'duration': 5.84},\n",
              " {'text': 'need to enable the GPU in your um collab',\n",
              "  'start': 383.88,\n",
              "  'duration': 4.24},\n",
              " {'text': \"otherwise you're going to get an error\",\n",
              "  'start': 386.68,\n",
              "  'duration': 3.639},\n",
              " {'text': \"that is GPU is not available and it's\",\n",
              "  'start': 388.12,\n",
              "  'duration': 4.0},\n",
              " {'text': 'not really possible to do this without',\n",
              "  'start': 390.319,\n",
              "  'duration': 4.16},\n",
              " {'text': 'GPU you can do it with CPU as well but',\n",
              "  'start': 392.12,\n",
              "  'duration': 4.76},\n",
              " {'text': \"it's going to be very slow okay so now\",\n",
              "  'start': 394.479,\n",
              "  'duration': 3.56},\n",
              " {'text': 'that you can see we have loaded the',\n",
              "  'start': 396.88,\n",
              "  'duration': 3.159},\n",
              " {'text': 'model we have gotten all this vocabulary',\n",
              "  'start': 398.039,\n",
              "  'duration': 3.6},\n",
              " {'text': 'we have gotten the tokenizer we have',\n",
              "  'start': 400.039,\n",
              "  'duration': 4.0},\n",
              " {'text': 'gotten the configuration and everything',\n",
              "  'start': 401.639,\n",
              "  'duration': 5.0},\n",
              " {'text': \"so now we are ready to go let's see the\",\n",
              "  'start': 404.039,\n",
              "  'duration': 4.6},\n",
              " {'text': 'results yeah we are printing out the',\n",
              "  'start': 406.639,\n",
              "  'duration': 4.081},\n",
              " {'text': 'results as you can see yeah this is as',\n",
              "  'start': 408.639,\n",
              "  'duration': 3.96},\n",
              " {'text': \"you can see it's like very good\",\n",
              "  'start': 410.72,\n",
              "  'duration': 4.24},\n",
              " {'text': \"punctuation I'm an algorithm full stop\",\n",
              "  'start': 412.599,\n",
              "  'duration': 4.081},\n",
              " {'text': \"I've covered log likelihood it which is\",\n",
              "  'start': 414.96,\n",
              "  'duration': 3.56},\n",
              " {'text': 'kind of a prerequisite full stop then',\n",
              "  'start': 416.68,\n",
              "  'duration': 5.199},\n",
              " {'text': \"comma a du let start it's pretty good\",\n",
              "  'start': 418.52,\n",
              "  'duration': 6.16},\n",
              " {'text': \"not um 100% accurate because it's not a\",\n",
              "  'start': 421.879,\n",
              "  'duration': 5.0},\n",
              " {'text': \"very good model but it's pretty good we\",\n",
              "  'start': 424.68,\n",
              "  'duration': 4.519},\n",
              " {'text': 'are going to use this okay so the next',\n",
              "  'start': 426.879,\n",
              "  'duration': 5.04},\n",
              " {'text': \"thing that we're going to do is um we're\",\n",
              "  'start': 429.199,\n",
              "  'duration': 4.881},\n",
              " {'text': 'going to use the chat GPT free version',\n",
              "  'start': 431.919,\n",
              "  'duration': 5.441},\n",
              " {'text': 'API version to get the results from this',\n",
              "  'start': 434.08,\n",
              "  'duration': 5.04},\n",
              " {'text': 'transcript so as you can see we have the',\n",
              "  'start': 437.36,\n",
              "  'duration': 3.04},\n",
              " {'text': 'transcript right here so we know the',\n",
              "  'start': 439.12,\n",
              "  'duration': 3.16},\n",
              " {'text': \"entire content of the video so it's\",\n",
              "  'start': 440.4,\n",
              "  'duration': 3.6},\n",
              " {'text': 'going to be piece of cake for now sounds',\n",
              "  'start': 442.28,\n",
              "  'duration': 3.52},\n",
              " {'text': \"good yeah so let's see we going to\",\n",
              "  'start': 444.0,\n",
              "  'duration': 3.52},\n",
              " {'text': 'import open', 'start': 445.8, 'duration': 4.0},\n",
              " {'text': \"AI as you can see I've already install\",\n",
              "  'start': 447.52,\n",
              "  'duration': 3.84},\n",
              " {'text': 'open a if you have not then you can do',\n",
              "  'start': 449.8,\n",
              "  'duration': 3.679},\n",
              " {'text': 'it using not equal to pip install open',\n",
              "  'start': 451.36,\n",
              "  'duration': 5.399},\n",
              " {'text': 'AI to the open AI API key', 'start': 453.479, 'duration': 5.601},\n",
              " {'text': 'website yeah as you can see right here',\n",
              "  'start': 456.759,\n",
              "  'duration': 5.44},\n",
              " {'text': 'this has API key you can just log in',\n",
              "  'start': 459.08,\n",
              "  'duration': 4.72},\n",
              " {'text': \"yeah you can just log in here's my API\",\n",
              "  'start': 462.199,\n",
              "  'duration': 3.081},\n",
              " {'text': \"key you can't see that just create a new\",\n",
              "  'start': 463.8,\n",
              "  'duration': 4.04},\n",
              " {'text': 'secret key write the key permissions all',\n",
              "  'start': 465.28,\n",
              "  'duration': 4.12},\n",
              " {'text': 'create secret key and you have the API',\n",
              "  'start': 467.84,\n",
              "  'duration': 3.639},\n",
              " {'text': \"key right here it's a it's it's very\",\n",
              "  'start': 469.4,\n",
              "  'duration': 4.759},\n",
              " {'text': 'easy sounds good now now we have the API',\n",
              "  'start': 471.479,\n",
              "  'duration': 4.44},\n",
              " {'text': 'key now we are having the', 'start': 474.159, 'duration': 4.48},\n",
              " {'text': \"prompt so let's have the prompt here so\",\n",
              "  'start': 475.919,\n",
              "  'duration': 4.201},\n",
              " {'text': \"as you can see right here let's go over\",\n",
              "  'start': 478.639,\n",
              "  'duration': 3.96},\n",
              " {'text': 'this so from open we importing open then',\n",
              "  'start': 480.12,\n",
              "  'duration': 4.519},\n",
              " {'text': 'we have the client with the API key just',\n",
              "  'start': 482.599,\n",
              "  'duration': 4.28},\n",
              " {'text': 'now we set and now this is the remember',\n",
              "  'start': 484.639,\n",
              "  'duration': 3.721},\n",
              " {'text': 'this this is very very easy and this is',\n",
              "  'start': 486.879,\n",
              "  'duration': 3.04},\n",
              " {'text': 'like very standard thing that we going',\n",
              "  'start': 488.36,\n",
              "  'duration': 3.239},\n",
              " {'text': 'to do so this is the way you have to',\n",
              "  'start': 489.919,\n",
              "  'duration': 4.601},\n",
              " {'text': 'access the uh openai API so we have the',\n",
              "  'start': 491.599,\n",
              "  'duration': 5.32},\n",
              " {'text': 'message here roll user content prompt so',\n",
              "  'start': 494.52,\n",
              "  'duration': 3.799},\n",
              " {'text': 'this is the prompt that we going to pass',\n",
              "  'start': 496.919,\n",
              "  'duration': 3.801},\n",
              " {'text': 'in um and then we are going to use a',\n",
              "  'start': 498.319,\n",
              "  'duration': 4.521},\n",
              " {'text': 'model GPT 3.5 turbo because the other',\n",
              "  'start': 500.72,\n",
              "  'duration': 4.12},\n",
              " {'text': \"GPD models are all paid we're not going\",\n",
              "  'start': 502.84,\n",
              "  'duration': 3.319},\n",
              " {'text': \"to use a paid version we're going to use\",\n",
              "  'start': 504.84,\n",
              "  'duration': 3.079},\n",
              " {'text': 'the free version and we have the',\n",
              "  'start': 506.159,\n",
              "  'duration': 3.961},\n",
              " {'text': 'temperature set equal to one it controls',\n",
              "  'start': 507.919,\n",
              "  'duration': 4.8},\n",
              " {'text': 'a Randomness basically Max tokens 2 56',\n",
              "  'start': 510.12,\n",
              "  'duration': 5.039},\n",
              " {'text': 'is the maximum number of tokens in the',\n",
              "  'start': 512.719,\n",
              "  'duration': 5.12},\n",
              " {'text': 'response um top P equal to 1 which means',\n",
              "  'start': 515.159,\n",
              "  'duration': 4.601},\n",
              " {'text': 'the op is a nuclear sampling parameter',\n",
              "  'start': 517.839,\n",
              "  'duration': 4.12},\n",
              " {'text': 'which is just another thing for uh like',\n",
              "  'start': 519.76,\n",
              "  'duration': 4.6},\n",
              " {'text': 'temperature just like temperature we we',\n",
              "  'start': 521.959,\n",
              "  'duration': 3.88},\n",
              " {'text': 'are determining the one with the higher',\n",
              "  'start': 524.36,\n",
              "  'duration': 5.12},\n",
              " {'text': 'probability Mass um frequency penalty is',\n",
              "  'start': 525.839,\n",
              "  'duration': 5.68},\n",
              " {'text': \"basically zero which means that we don't\",\n",
              "  'start': 529.48,\n",
              "  'duration': 4.64},\n",
              " {'text': 'want the model to repeat anything and',\n",
              "  'start': 531.519,\n",
              "  'duration': 4.241},\n",
              " {'text': 'prence penalty is also zero which means',\n",
              "  'start': 534.12,\n",
              "  'duration': 2.92},\n",
              " {'text': 'that we do not want it to add', 'start': 535.76, 'duration': 3.68},\n",
              " {'text': 'unnecessary words or just making it for',\n",
              "  'start': 537.04,\n",
              "  'duration': 3.96},\n",
              " {'text': 'veros without any reason for example if',\n",
              "  'start': 539.44,\n",
              "  'duration': 3.079},\n",
              " {'text': \"you're asking for one word just reply\",\n",
              "  'start': 541.0,\n",
              "  'duration': 4.36},\n",
              " {'text': \"with one word don't be any like verbos\",\n",
              "  'start': 542.519,\n",
              "  'duration': 4.681},\n",
              " {'text': \"and explain why you're saying that and\",\n",
              "  'start': 545.36,\n",
              "  'duration': 4.84},\n",
              " {'text': \"all that you don't want that right um so\",\n",
              "  'start': 547.2,\n",
              "  'duration': 4.199},\n",
              " {'text': \"let's run\", 'start': 550.2, 'duration': 3.4},\n",
              " {'text': 'this great now we have the response',\n",
              "  'start': 551.399,\n",
              "  'duration': 3.88},\n",
              " {'text': 'right here simple thing just print it',\n",
              "  'start': 553.6,\n",
              "  'duration': 3.44},\n",
              " {'text': 'out so this is the way you can print out',\n",
              "  'start': 555.279,\n",
              "  'duration': 3.721},\n",
              " {'text': 'the response is very important chat',\n",
              "  'start': 557.04,\n",
              "  'duration': 4.68},\n",
              " {'text': 'completion. choices z. message. content',\n",
              "  'start': 559.0,\n",
              "  'duration': 4.64},\n",
              " {'text': 'this is the way it actually comes in so',\n",
              "  'start': 561.72,\n",
              "  'duration': 3.2},\n",
              " {'text': 'if you want to see what the chat',\n",
              "  'start': 563.64,\n",
              "  'duration': 2.8},\n",
              " {'text': 'completion looks like you can check it',\n",
              "  'start': 564.92,\n",
              "  'duration': 3.8},\n",
              " {'text': \"out it's actually kind of a dictionary\",\n",
              "  'start': 566.44,\n",
              "  'duration': 4.28},\n",
              " {'text': \"uh it's kind of a class here where you\",\n",
              "  'start': 568.72,\n",
              "  'duration': 4.32},\n",
              " {'text': 'have different attributes so this is the',\n",
              "  'start': 570.72,\n",
              "  'duration': 4.84},\n",
              " {'text': 'content that we want um so that is why',\n",
              "  'start': 573.04,\n",
              "  'duration': 4.56},\n",
              " {'text': \"we are doing this so let's see the\",\n",
              "  'start': 575.56,\n",
              "  'duration': 3.399},\n",
              " {'text': 'content so the test discusses the',\n",
              "  'start': 577.6,\n",
              "  'duration': 3.08},\n",
              " {'text': 'derivation and maths focusing on binary',\n",
              "  'start': 578.959,\n",
              "  'duration': 4.681},\n",
              " {'text': 'classification perfect destion boundary',\n",
              "  'start': 580.68,\n",
              "  'duration': 4.719},\n",
              " {'text': 'uh like likelihood function sigmoid',\n",
              "  'start': 583.64,\n",
              "  'duration': 4.199},\n",
              " {'text': 'function gradient descent optimal',\n",
              "  'start': 585.399,\n",
              "  'duration': 4.12},\n",
              " {'text': 'parameters like Theta it controls by',\n",
              "  'start': 587.839,\n",
              "  'duration': 3.801},\n",
              " {'text': 'discussing how to determine the equation',\n",
              "  'start': 589.519,\n",
              "  'duration': 4.121},\n",
              " {'text': 'in theeta transpose X comprehensive',\n",
              "  'start': 591.64,\n",
              "  'duration': 3.92},\n",
              " {'text': 'explanation and its implementation so',\n",
              "  'start': 593.64,\n",
              "  'duration': 4.759},\n",
              " {'text': \"well it's your cue to go and study this\",\n",
              "  'start': 595.56,\n",
              "  'duration': 6.12},\n",
              " {'text': 'classification um video as well but yeah',\n",
              "  'start': 598.399,\n",
              "  'duration': 4.761},\n",
              " {'text': \"you can do it at your own pace but it's\",\n",
              "  'start': 601.68,\n",
              "  'duration': 3.88},\n",
              " {'text': 'a very important thing as well sorry not',\n",
              "  'start': 603.16,\n",
              "  'duration': 4.64},\n",
              " {'text': 'sorry a little bit of promotion but yeah',\n",
              "  'start': 605.56,\n",
              "  'duration': 4.2},\n",
              " {'text': 'now we done so now you can just take on',\n",
              "  'start': 607.8,\n",
              "  'duration': 4.52},\n",
              " {'text': 'a prompt which is any kind of prompt',\n",
              "  'start': 609.76,\n",
              "  'duration': 4.639},\n",
              " {'text': \"that you want uh why don't why just\",\n",
              "  'start': 612.32,\n",
              "  'duration': 5.36},\n",
              " {'text': \"change this let's just have this one\",\n",
              "  'start': 614.399,\n",
              "  'duration': 5.801},\n",
              " {'text': \"right here so let's change it to I don't\",\n",
              "  'start': 617.68,\n",
              "  'duration': 4.44},\n",
              " {'text': 'know anything you want', 'start': 620.2, 'duration': 5.759},\n",
              " {'text': 'maybe um', 'start': 622.12, 'duration': 3.839},\n",
              " {'text': 'answer questions based on', 'start': 626.44, 'duration': 5.959},\n",
              " {'text': \"this text you have right here so let's\",\n",
              "  'start': 629.959,\n",
              "  'duration': 5.68},\n",
              " {'text': 'add a question um what do you want me to',\n",
              "  'start': 632.399,\n",
              "  'duration': 5.841},\n",
              " {'text': \"add let's\", 'start': 635.639, 'duration': 6.44},\n",
              " {'text': 'say what is', 'start': 638.24, 'duration': 3.839},\n",
              " {'text': 'classification what is exactly taught',\n",
              "  'start': 644.6,\n",
              "  'duration': 4.32},\n",
              " {'text': \"here let's see what it has to say\",\n",
              "  'start': 649.48,\n",
              "  'duration': 6.359},\n",
              " {'text': 'algorithm predict the class speaker well',\n",
              "  'start': 653.16,\n",
              "  'duration': 4.56},\n",
              " {'text': \"it's not my name but whatever we have\",\n",
              "  'start': 655.839,\n",
              "  'duration': 4.12},\n",
              " {'text': 'put it in the transcript so derivation',\n",
              "  'start': 657.72,\n",
              "  'duration': 3.96},\n",
              " {'text': 'and math specifically binary', 'start': 659.959, 'duration': 4.12},\n",
              " {'text': 'classification uh okay my gender is also',\n",
              "  'start': 661.68,\n",
              "  'duration': 5.279},\n",
              " {'text': 'wrong but whatever decision boundary and',\n",
              "  'start': 664.079,\n",
              "  'duration': 5.241},\n",
              " {'text': 'then dering the this one radiant descent',\n",
              "  'start': 666.959,\n",
              "  'duration': 4.841},\n",
              " {'text': 'see is perfect the answer is perfect key',\n",
              "  'start': 669.32,\n",
              "  'duration': 4.92},\n",
              " {'text': 'Concepts it um and steps involving',\n",
              "  'start': 671.8,\n",
              "  'duration': 4.2},\n",
              " {'text': 'binary classification retailed', 'start': 674.24, 'duration': 3.2},\n",
              " {'text': 'description as you can see this is',\n",
              "  'start': 676.0,\n",
              "  'duration': 3.48},\n",
              " {'text': 'extremely good um I also show you how',\n",
              "  'start': 677.44,\n",
              "  'duration': 3.519},\n",
              " {'text': 'you can deploy this from n to end but',\n",
              "  'start': 679.48,\n",
              "  'duration': 3.84},\n",
              " {'text': \"that's for another video okay take care\",\n",
              "  'start': 680.959,\n",
              "  'duration': 4.801},\n",
              " {'text': 'bye', 'start': 683.32, 'duration': 2.44}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxez_p1IXXIH"
      },
      "outputs": [],
      "source": [
        "transcript_joined=\" \".join(line['text'] for line in transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "UN0QQneEXXKt",
        "outputId": "ee90187d-2971-462d-a993-79e0767022c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"hello everyone I am Santi and I'm currently working as an ml engineer today we are going to do an awesome machine learning project that you can add to your resume and impress all the interviewers um I'm dedicated to teaching machine learning to all of you and to ensure that you all learned an ml job as soon as possible okay so without any further Ado let's Dive Right In so our title is going to be um so our project title is going to be uh YouTube video summarizer with llm well so what's going to do is going to take in a video and you can ask any question regarding the videos contents the images Etc and that's going to be really really good really useful as well and that can be a mini deployed project as well okay so first things first um let's let's let's think about why do we need this in the first place the interviewer might say why not just use chat GPT right because chat gpg has now enabled the search web feature for every free user right so you might be wondering why not just use that okay so let's see why we are not going to use that as you can see right here we have our chat GPT open and let's see um which video are we going to use yeah so this is a video that we are going to use right here as you can see my binary classification video which is of the length of 32 32 minutes okay so let's put this inside the chat GPD and I will the search web feature and say write the transcript for this this for this video because first of all we'll need the transcript right as you can see right here it says that it's unable to actually get the video um transcript so if you don't have the transcript obviously then you won't be able to do anything with it right okay whenever you get any project it's very important to understand that you first need to break the project down into smaller pieces that you can tackle easily this is very important because if you think that how how am I going to do that we don't have this we don't have that at the first so this going to be very confusing so let's tackle it one by one step by step remember this for any project that you are going to do okay I'm going to use Google collab here because we need GPU for our support so if you don't have GPU on your system or you're using any Windows system you're using a Mac system whatever it is it doesn't matter as long as you have Google collab you can just go in it's free for you to use and you can do the project here and in your resume you can just put in link okay so let's do first install let's first install the YouTube transcript API great now we have the YouTube trans transcript API so now what we going to do is basically get the link provide the link to the video um to this library and generate the transcript using this now we're going to import the YouTube transcript API so from YouTube YouTube transcript API sounds good now let's get the video ID from the um video so what we going to do is basically as you know this is the video right here and this is the video ID so whenever you put in a link you're going to get the video ID from here get video ID is going to be this function great you now have the video ID so let's see what the video ID looks like um copy this yeah this is the video ID yeah next thing is getting the transcript so basically get video ID we already have that so let's just store it in a variable this one going to be video ID um yeah sounds good now let's see what the transcript looks like yeah as you can see this is what the transcript looks like so now what you're going to do is uh add all this together yep yeah so now what we going to do is do the transcript join so what does it going to look like exactly just join this together all the text features that you have in this transcript great now we can see what the transcript joint looks like yeah great as you can see right here this is our transcript that we have um okay as you can see we have it Santi but we can't do anything about it so let's just forget about it for the moment yeah um sounds good now what we going to do is basically we need to as you can see the transcript that you saw um it does not actually have a proper punctuation so we going to put in the punctuation now how we're going to do that we're going to use a model for that this is where the llm comes into the play okay so now as you can see like uh restoring the punctuation this is called a library which we have actually and this is actually a restore Punk Library yeah this is our Punk library that we have actually but there's a problem out here the versions are very like old because it's three years ago so that is why there's a patch for the Same by another uh GitHub user so that that is what we are going to use here great so this is actually the thing please note it down because you're going to need this if you use the normal ARB it's not going to help great now the next thing comes is restoring the punctuations so from the r pun we going to import restore puns and then you're going to use this restore Punk function so what this actually does behind the scenes is it uses a model from the hugging face library and this model is actually loaded here and this model is actually pre-trained for taking in bunch of text and then um getting the punctu ation back to that text great now that this is done let's move on to the um getting the results from the punctuation so as you can see right here this one py toch model this model actually got loaded so one thing if you facing some problem with GPU it's very important to use this actually um here yeah as you can see right here we have GPU enable T4 so you need to enable the GPU in your um collab otherwise you're going to get an error that is GPU is not available and it's not really possible to do this without GPU you can do it with CPU as well but it's going to be very slow okay so now that you can see we have loaded the model we have gotten all this vocabulary we have gotten the tokenizer we have gotten the configuration and everything so now we are ready to go let's see the results yeah we are printing out the results as you can see yeah this is as you can see it's like very good punctuation I'm an algorithm full stop I've covered log likelihood it which is kind of a prerequisite full stop then comma a du let start it's pretty good not um 100% accurate because it's not a very good model but it's pretty good we are going to use this okay so the next thing that we're going to do is um we're going to use the chat GPT free version API version to get the results from this transcript so as you can see we have the transcript right here so we know the entire content of the video so it's going to be piece of cake for now sounds good yeah so let's see we going to import open AI as you can see I've already install open a if you have not then you can do it using not equal to pip install open AI to the open AI API key website yeah as you can see right here this has API key you can just log in yeah you can just log in here's my API key you can't see that just create a new secret key write the key permissions all create secret key and you have the API key right here it's a it's it's very easy sounds good now now we have the API key now we are having the prompt so let's have the prompt here so as you can see right here let's go over this so from open we importing open then we have the client with the API key just now we set and now this is the remember this this is very very easy and this is like very standard thing that we going to do so this is the way you have to access the uh openai API so we have the message here roll user content prompt so this is the prompt that we going to pass in um and then we are going to use a model GPT 3.5 turbo because the other GPD models are all paid we're not going to use a paid version we're going to use the free version and we have the temperature set equal to one it controls a Randomness basically Max tokens 2 56 is the maximum number of tokens in the response um top P equal to 1 which means the op is a nuclear sampling parameter which is just another thing for uh like temperature just like temperature we we are determining the one with the higher probability Mass um frequency penalty is basically zero which means that we don't want the model to repeat anything and prence penalty is also zero which means that we do not want it to add unnecessary words or just making it for veros without any reason for example if you're asking for one word just reply with one word don't be any like verbos and explain why you're saying that and all that you don't want that right um so let's run this great now we have the response right here simple thing just print it out so this is the way you can print out the response is very important chat completion. choices z. message. content this is the way it actually comes in so if you want to see what the chat completion looks like you can check it out it's actually kind of a dictionary uh it's kind of a class here where you have different attributes so this is the content that we want um so that is why we are doing this so let's see the content so the test discusses the derivation and maths focusing on binary classification perfect destion boundary uh like likelihood function sigmoid function gradient descent optimal parameters like Theta it controls by discussing how to determine the equation in theeta transpose X comprehensive explanation and its implementation so well it's your cue to go and study this classification um video as well but yeah you can do it at your own pace but it's a very important thing as well sorry not sorry a little bit of promotion but yeah now we done so now you can just take on a prompt which is any kind of prompt that you want uh why don't why just change this let's just have this one right here so let's change it to I don't know anything you want maybe um answer questions based on this text you have right here so let's add a question um what do you want me to add let's say what is classification what is exactly taught here let's see what it has to say algorithm predict the class speaker well it's not my name but whatever we have put it in the transcript so derivation and math specifically binary classification uh okay my gender is also wrong but whatever decision boundary and then dering the this one radiant descent see is perfect the answer is perfect key Concepts it um and steps involving binary classification retailed description as you can see this is extremely good um I also show you how you can deploy this from n to end but that's for another video okay take care bye\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transcript_joined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mJYr6gQdE3U",
        "outputId": "27048f21-a3bd-4b88-e799-92b2f1f8863c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/babthamotharan/rpunct.git@patch-2\n",
            "  Cloning https://github.com/babthamotharan/rpunct.git (to revision patch-2) to /tmp/pip-req-build-fghrt31x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/babthamotharan/rpunct.git /tmp/pip-req-build-fghrt31x\n",
            "  Running command git checkout -b patch-2 --track origin/patch-2\n",
            "  Switched to a new branch 'patch-2'\n",
            "  Branch 'patch-2' set up to track remote branch 'patch-2' from 'origin'.\n",
            "  Resolved https://github.com/babthamotharan/rpunct.git to commit a87b93410ca782657abb4e34df9159e6e47ac9ec\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langdetect>=1.0.9 (from rpunct==1.0.2)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from rpunct==1.0.2) (2.2.2)\n",
            "Collecting simpletransformers>=0.61.4 (from rpunct==1.0.2)\n",
            "  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from rpunct==1.0.2) (1.17.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from rpunct==1.0.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2024.11.6)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.14.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (1.6.1)\n",
            "Collecting seqeval (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.18.0)\n",
            "Collecting tensorboardx (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.21.1)\n",
            "Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.19.11)\n",
            "Collecting streamlit (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->rpunct==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (0.31.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (0.5.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.11.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (75.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (2025.4.26)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (3.11.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->rpunct==1.0.2) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->simpletransformers>=0.61.4->rpunct==1.0.2) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->simpletransformers>=0.61.4->rpunct==1.0.2) (3.6.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (5.5.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (11.2.1)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (6.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (1.38.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (0.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.24.0)\n",
            "Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rpunct, langdetect, seqeval\n",
            "  Building wheel for rpunct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpunct: filename=rpunct-1.0.2-py3-none-any.whl size=5887 sha256=339e83376ef1a90617400e9a8f908aea315d1b664e33ad1d0d098b38a0b3c7e2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m8otbsu4/wheels/be/5b/6a/bc4b174e97ac0584ce55ca312be4310c1e76ed17db89e8dc32\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=d8a8483804ba18e5a2cefa50d46a7e21a1954b66a3155d0aafdca81ab9b984c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=be893e2b903aa52a0d2c557d94fc59535e861a6bfe48a68456180fa5484012ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built rpunct langdetect seqeval\n",
            "Installing collected packages: watchdog, tensorboardx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, seqeval, nvidia-cusolver-cu12, streamlit, simpletransformers, rpunct\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed langdetect-1.0.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydeck-0.9.1 rpunct-1.0.2 seqeval-1.2.2 simpletransformers-0.70.1 streamlit-1.45.1 tensorboardx-2.6.2.2 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "# for punctuations (updated)\n",
        "\n",
        "!pip install git+https://github.com/babthamotharan/rpunct.git@patch-2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAkyRytliewJ",
        "outputId": "cad7707c-0c2e-41c6-ef1a-f2414f92e96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwbiOypFe-yY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "5d1bebbaf3a34195adf556dc926b4a39",
            "c3d1bcdfac274680a4ced2c1eb41df74",
            "96e8dac9fe7d4b09990b0a9b1f213b50",
            "51dfa8db1c014aff8604219a9b6021d2",
            "19beb8f760e0486eb5723e9af527b2fc",
            "4b455a180b6742209f58f8d5741e64fe",
            "76c0348a128542558e30b445f2f643a7",
            "8d79080d17254ecd994e25a88d04b405",
            "189ef7fe1c6e4132a64977a432268ad5",
            "0be8e02bc4c143c0b53e5e5c26dcf1c8",
            "8bdbf395297141dda62dccb263348c2d",
            "6033e8b0df704663a811453457e7e0f2",
            "4d853c614d704bd882c7757b31fc03a9",
            "432e783141b24a95b16825c6e0a7a8e8",
            "268d3b9abf9b45a0a502872a065c557c",
            "ea9b29c6a6d34eb09dbf57030cd466ed",
            "c397e9778d1f4b37a9391c09db413da5",
            "eba1a99f32f9492cbdafe1d5f25cedf1",
            "e16a064381c64f25bc49a42e6281ab4e",
            "c2636da1aa30457ba66dbcd14b11ea86",
            "82c20d5afb4a4b2b9fda88071fc662a5",
            "5c0e652d568949bfa942f6aae4546d94",
            "8e55a868ed124e7ba90159ec54ce887f",
            "8bc814dec52f4b11b801fd8279af4a11",
            "243dd4872a3040ff9d4a85d8981676e9",
            "a0e95f47eb774c6db83b58879a896dc3",
            "3d11755a7d234cdc8052b744332717c7",
            "6cb23d30d38c495fb0dcfffb8e27ab28",
            "a35730e56c694aa2bc3b3690d6163880",
            "f0f3cba5e3824566b54cd4f07f1fbd71",
            "42a05e2cbe4b4401816eb529f5879ed1",
            "d15d391518f24cbcb4fd92d6167bd488",
            "4da58830f73b4c528493265326026b41",
            "dee83e00fc0e4c1b9bb876d9f60025ed",
            "d6603dcefe1042799e72f65f5f0de934",
            "a0f164e851dc4cf38eca17d297abbfcf",
            "ccc7ac82d1a44aa59f12361a9f77435c",
            "e5b4ded596004f66b15a3f17c24fd34b",
            "2594bbaa98154941a2464fe9932ff81c",
            "e69da485e3c449e08613cfbd4537da7a",
            "41682767bf44447f85ea71a37568fa39",
            "0f55015fbdf64f14a90cac09eb0fdd7c",
            "3613c8602ef74f9598c083e14d7df166",
            "87299d449bc84fd5892da0cdeb5bba8f",
            "9aeb6df6740145d58be1cae82bc0849c",
            "7e448f316927473698dba81f740f16fb",
            "477388a5c66d4c888cef2756d30fe06b",
            "5a78791b81ea4d4fbf95a722b47f0392",
            "a786ae506751465da67e052eb0565fd8",
            "12467fdae7ef484a9777a8084db2b294",
            "48d9f6274e1743c68de1cf2c7ab4a81f",
            "eb32cf4dc47c4d72b5e7590d6de61c87",
            "28966a94e2664c9b9c1bb388b8030c34",
            "c2543e470b9347f58b0ffe58c22761e5",
            "0b98b4b462104386afc9a680c0b6b464",
            "7034fe327d1f4f638b19576fac8eaf6d",
            "989c0a35b3c44a4c872eb2f8da7f2f17",
            "45f3e236555e47bb9c28f8363d7ba98b",
            "ab974424e78542819bbec08adc84a05f",
            "73ba5da47a684e46851e683b7c800677",
            "3ad9171d42364b23876b7be78442dcef",
            "a55f8b8315154416a78eafd116198c73",
            "e67112cbfded431890a5f444c2a86376",
            "c914e3713eb940db9c2589857a680739",
            "64277d0fdcf24cecbe1fb62e4d6255d6",
            "257719a06099423987c3c99aa1ed081c"
          ]
        },
        "id": "cGvjCKldlFkV",
        "outputId": "b8a4b7d6-1644-423f-84c0-d69cd9ebc1e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d1bebbaf3a34195adf556dc926b4a39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6033e8b0df704663a811453457e7e0f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e55a868ed124e7ba90159ec54ce887f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/530 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dee83e00fc0e4c1b9bb876d9f60025ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aeb6df6740145d58be1cae82bc0849c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7034fe327d1f4f638b19576fac8eaf6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from rpunct import RestorePuncts\n",
        "rpunct = RestorePuncts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riaaA9-alFws",
        "outputId": "a859fa31-7950-4c5b-aec4-b7c00aab2567"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/simpletransformers/ner/ner_model.py:1643: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Everyone! I am Santi and I'm currently working as an Ml engineer. Today We are going to do an awesome machine learning project that you can add to your resume and impress all the interviewers. Um, I'm dedicated to teaching machine learning to all of you and to ensure that you all learned an Ml job as soon as possible. Okay, so without any further, Ado Let's Dive Right In So our title is going to be Um, so our project title is going to be uh YouTube Video summarizer with Llm. Well, so what's going to do is going to take in a video and you can ask any question regarding the videos contents, the images Etc and that's going to be really, really good. Really useful as well and that can be a mini deployed project as well. Okay, so first things first. Um, let's let's let's think about why do we need this in the first place? The interviewer might say, why not just use chat GPT right? Because Chat Gpg has now enabled the search web feature for every free user, right? So you might be wondering, why not just use that? Okay, so let's see why we are not going to use that As you can see right here we have our chat GPT open and let's see um, which video are we going to use. Yeah, so this is a video that we are going to use right here as you can see my binary classification video which is of the length of 32 32 minutes. Okay, so let's put this inside the chat GPD and I will the search web feature and say write the transcript for this. This for this video because first of all, we'll need the transcript right. As you can see right here, it says that it's unable to actually get the video um transcript. So if you don't have the transcript obviously then you won't be able to do anything with it, right? Okay, whenever you get any project, it's very important to understand that you first need to break the project down into smaller pieces that you can tackle easily. This is very important because if you think that how how am I going to do that, we don't have this. We don't have that at the first so this going to be very confusing. So let's tackle it one by one. step by step. Remember this for any project that you are going to do Okay I'm going to use Google Collab here because we need GPU for our support. So if you don't have GPU on your system or you're using any Windows system, you're using a Mac system. Whatever it is, it doesn't matter. As long as you have Google collab, you can just go in. It's free for you to use and you can do the project here and in your resume. you can just put in link. Okay, so let's do first install. Let's first install the YouTube transcript API Great! Now we have the YouTube trans transcript API So now what we going to do is basically get the link, provide the link to the video, um to this library and generate the transcript using this. Now we're going to import the YouTube transcript API So from YouTube YouTube Transcript API Sounds good. Now let's get the video ID from the Um video. So what we going to do is basically as you know, this is the video right here and this is the video. ID So whenever you put in a link, you're going to get the video ID From here, get video ID Is going to be this function great. You now have the video ID So let's see what the video ID looks like. Um, copy this. Yeah, this is the video ID Yeah, Next thing is getting the transcript. So basically get video ID We already have that. so let's just store it in a variable. This one going to be video ID Um yeah, sounds good. Now let's see what the transcript looks like. Yeah, as you can see, this is what the transcript looks like. So now what you're going to do is uh, add all this together. Yep, yeah. So now what we going to do is do the transcript join. So what does it going to look like Exactly, Just join this together all the text features that you have in this transcript. Great! Now we can see what the transcript joint looks like. Yeah, great as you can see right here this is our transcript that we have. Um okay as you can see, we have it Santi But we can't do anything about it so let's just forget about it for the moment. Yeah, um sounds good. Now what we going to do is basically we need to as you can see the transcript that you saw um, it does not actually have a proper punctuation. So we going to put in the punctuation. Now how we're going to do that, We're going to use a model for that. This is where the Llm comes into the play. Okay so now as you can see like uh, restoring the punctuation, this is called a library which we have actually and this is actually a Restore Punk Library Yeah, this is our Punk library that we have actually, but there's a problem out here. The versions are very like old because it's three years ago. So that is why there's a patch for the Same by another uh GitHub user. so that that is what we are going to use here. Great! So this is actually the thing. Please note it down because you're going to need this if you use the normal ARB it's not going to help great. Now the next thing comes is restoring the punctuations. So from the r pun we going to import restore puns and then you're going to use this restore Punk function. So what this actually does behind the scenes is it uses a model from the Hugging Face library and this model is actually loaded here and this model is actually pre-trained for taking in bunch of text and then um getting the punctu ation back to that text. Great! Now that this is done, let's move on to the Um getting the results from the punctuation. So as you can see right here this one Py Toch model, this model actually got loaded. So one thing if you facing some problem with GPU it's very important to use this actually. Um here. Yeah, as you can see right here we have GPU enable T4 So you need to enable the GPU in your Um collab. otherwise you're going to get an error that is GPU is not available and it's not really possible to do this without GPU You can do it with CPU as well but it's going to be very slow. Okay so now that you can see we have loaded the model, We have gotten all this vocabulary, We have gotten the tokenizer, we have gotten the configuration and everything so now we are ready to go. Let's see the results. Yeah we are printing out the results as you can see. Yeah this is as you can see it's like very good punctuation. I'm an algorithm full stop I've covered log likelihood it which is kind of a prerequisite full stop then comma a du Let start it's pretty good. Not um 100% accurate because it's not a very good model. but it's pretty good. We are going to use this. Okay so the next thing that we're going to do is um we're going to use the chat GPT free version API version to get the results from this transcript. So as you can see we have the transcript right here so we know the entire content of the video so it's going to be piece of cake for now. Sounds good? Yeah so let's see we going to import Open AI as you can see I've already install Open A If you have not then you can do it using not equal to pip install Open AI to the Open AI API Key Website Yeah as you can see right here this has API key. You can just log in. Yeah you can just log in. Here's my API key. You can't see that. Just create a new secret key, write the key, permissions all create secret key and you have the API key right here. It's A It's it's very easy. Sounds good. Now Now we have the API key. Now we are having the prompt so let's have the prompt here. So as you can see right here let's go over this. So from open we importing open then we have the client with the API key. Just now we set and now this is the remember this This is very very easy and this is like very standard thing that we going to do. So this is the way you have to access the Uh Openai API So we have the message here: roll user content prompt. So this is the prompt that we going to pass in. Um and then we are going to use a model GPT 3.5 turbo. Because the other GPD models are all paid, we're not going to use a paid version. We're going to use the free version and we have the temperature set equal to one. It controls a Randomness Basically Max Tokens 2 56 is the maximum number of tokens in the response. um top P equal to 1 Which means the Op is a nuclear sampling parameter which is just another thing for uh, like temperature. Just like temperature, we we are determining the one with the higher probability Mass um. Frequency penalty is basically zero, which means that we don't want the model to repeat anything. and prence penalty is also zero. Which means that we do not want it to add unnecessary words or just making it for Veros without any reason. For example, if you're asking for one word, just reply with one word. don't be any like verbos and explain why you're saying that and all that you don't want that right? Um, so let's run this great. Now we have the response right here. Simple thing: just print it out. So this is the way you can print out. The response is very important. Chat completion. choices, Z. message. content. This is the way it actually comes in. so if you want to see what the chat completion looks like, you can check it out. It's actually kind of a dictionary. Uh, it's kind of a class here where you have different attributes. so this is the content that we want. Um, so that is why we are doing this. So let's see the content. So the test discusses the derivation and maths, focusing on binary classification. Perfect destion boundary uh, like likelihood function, sigmoid function, gradient descent, optimal parameters like Theta It controls by discussing how to determine the equation in theeta transpose X Comprehensive explanation and its implementation so well. it's your cue to go and study this classification. um, video as well. But yeah, you can do it at your own pace. but it's a very important thing as well. Sorry, not sorry. a little bit of promotion, but yeah, now we done. So now you can just take on a prompt which is any kind of prompt that you want. Uh, why don't Why just change this? Let's just have this one right here. So let's change it to: I Don't know anything you want? Maybe, um, answer questions based on this text you have right here. So let's add a question. Um, what do you want me to add? Let's say what is classification? What is exactly taught here? Let's see what it has to say. Algorithm: Predict the class Speaker: Well, it's not my name, but whatever we have put it in the transcript. So derivation and math specifically binary classification. Uh okay, my gender is also wrong, but whatever. decision boundary and then dering the this one radiant descent see is perfect. The answer is perfect. Key: Concepts It: Um and steps involving binary classification retailed Description: As you can see, this is extremely good. Um I Also, show you how you can deploy this from n to end but that's for another video. Okay, take care bye.\n"
          ]
        }
      ],
      "source": [
        "results = rpunct.punctuate(transcript_joined)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDC4z4nxlFzh"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8S5PbX6lF2Y"
      },
      "outputs": [],
      "source": [
        "api_key = \"your_openapi_key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSy8xVEhlF5f"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Based on the following transcript, answer the question.\n",
        "\n",
        "Transcript:\n",
        "{transcript_joined}\n",
        "\n",
        "Question:\n",
        "How is punctuation restored in the transcript?\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5YMWIY8lF8Z"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=api_key  # This is the default and can be omitted\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=1, # Temperature controls randomness in the response\n",
        "    max_tokens=256, # Maximum number of tokens in the response\n",
        "    top_p=1, # Top-p (nucleus) sampling parameter, higher values make output more focused\n",
        "    frequency_penalty=0, # Frequency penalty discourages the model from repeating words or phrases\n",
        "    presence_penalty=0 # Presence penalty discourages the model from adding verbose or unnecessary words\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNZz2pSJlF_q",
        "outputId": "9933a0bd-7cf1-4f44-ee32-192656c92eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Punctuation is restored in the transcript by using a model from the hugging face library. The model is pre-trained to take in a bunch of text and then add the correct punctuation back to the text. This process is achieved by using the 'restore_punc' function from the library.\n"
          ]
        }
      ],
      "source": [
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW-enE_5lGCs",
        "outputId": "6cee5df6-f4c0-4249-df53-ed661931c6b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-BX6P2R4WV1X9pJRHMJy1ZMXWPTmHp', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='1. What is the project title mentioned in the text?\\n- The project title mentioned in the text is \"YouTube video summarizer with llm\".\\n\\n2. Why is it important to break down a project into smaller pieces according to the text?\\n- It is important to break down a project into smaller pieces to tackle it easily and avoid confusion.\\n\\n3. How is punctuation restored in the text using a model?\\n- Punctuation is restored in the text using a model from the hugging face library that is pre-trained to add punctuation to text.\\n\\n4. What API key is required for using the OpenAI API mentioned in the text?\\n- An API key from the OpenAI API website is required to access the OpenAI API.\\n\\n5. What are some of the parameters set for the GPT model in the text?\\n- Some of the parameters set for the GPT model in the text include temperature, max tokens, top P, frequency penalty, and presence penalty.\\n\\n6. What is the prompt used to generate a response from the GPT model in the text?\\n- The prompt used to generate a response from the GPT model in the text is \"answer questions based on this text you have right here\".\\n\\n7. How is the response printed out in the text after using', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1747229136, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=256, prompt_tokens=2272, total_tokens=2528, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_completion"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b98b4b462104386afc9a680c0b6b464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0be8e02bc4c143c0b53e5e5c26dcf1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f55015fbdf64f14a90cac09eb0fdd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12467fdae7ef484a9777a8084db2b294": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189ef7fe1c6e4132a64977a432268ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19beb8f760e0486eb5723e9af527b2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243dd4872a3040ff9d4a85d8981676e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0f3cba5e3824566b54cd4f07f1fbd71",
            "max": 530,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42a05e2cbe4b4401816eb529f5879ed1",
            "value": 530
          }
        },
        "257719a06099423987c3c99aa1ed081c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2594bbaa98154941a2464fe9932ff81c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268d3b9abf9b45a0a502872a065c557c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c20d5afb4a4b2b9fda88071fc662a5",
            "placeholder": "​",
            "style": "IPY_MODEL_5c0e652d568949bfa942f6aae4546d94",
            "value": " 436M/436M [00:02&lt;00:00, 142MB/s]"
          }
        },
        "28966a94e2664c9b9c1bb388b8030c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3613c8602ef74f9598c083e14d7df166": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad9171d42364b23876b7be78442dcef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d11755a7d234cdc8052b744332717c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41682767bf44447f85ea71a37568fa39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a05e2cbe4b4401816eb529f5879ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "432e783141b24a95b16825c6e0a7a8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e16a064381c64f25bc49a42e6281ab4e",
            "max": 435701303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2636da1aa30457ba66dbcd14b11ea86",
            "value": 435701303
          }
        },
        "45f3e236555e47bb9c28f8363d7ba98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67112cbfded431890a5f444c2a86376",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c914e3713eb940db9c2589857a680739",
            "value": 112
          }
        },
        "477388a5c66d4c888cef2756d30fe06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb32cf4dc47c4d72b5e7590d6de61c87",
            "max": 435640264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28966a94e2664c9b9c1bb388b8030c34",
            "value": 435640264
          }
        },
        "48d9f6274e1743c68de1cf2c7ab4a81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b455a180b6742209f58f8d5741e64fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d853c614d704bd882c7757b31fc03a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c397e9778d1f4b37a9391c09db413da5",
            "placeholder": "​",
            "style": "IPY_MODEL_eba1a99f32f9492cbdafe1d5f25cedf1",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4da58830f73b4c528493265326026b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51dfa8db1c014aff8604219a9b6021d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be8e02bc4c143c0b53e5e5c26dcf1c8",
            "placeholder": "​",
            "style": "IPY_MODEL_8bdbf395297141dda62dccb263348c2d",
            "value": " 1.25k/1.25k [00:00&lt;00:00, 115kB/s]"
          }
        },
        "5a78791b81ea4d4fbf95a722b47f0392": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2543e470b9347f58b0ffe58c22761e5",
            "placeholder": "​",
            "style": "IPY_MODEL_0b98b4b462104386afc9a680c0b6b464",
            "value": " 436M/436M [00:07&lt;00:00, 29.0MB/s]"
          }
        },
        "5c0e652d568949bfa942f6aae4546d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d1bebbaf3a34195adf556dc926b4a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3d1bcdfac274680a4ced2c1eb41df74",
              "IPY_MODEL_96e8dac9fe7d4b09990b0a9b1f213b50",
              "IPY_MODEL_51dfa8db1c014aff8604219a9b6021d2"
            ],
            "layout": "IPY_MODEL_19beb8f760e0486eb5723e9af527b2fc"
          }
        },
        "6033e8b0df704663a811453457e7e0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d853c614d704bd882c7757b31fc03a9",
              "IPY_MODEL_432e783141b24a95b16825c6e0a7a8e8",
              "IPY_MODEL_268d3b9abf9b45a0a502872a065c557c"
            ],
            "layout": "IPY_MODEL_ea9b29c6a6d34eb09dbf57030cd466ed"
          }
        },
        "64277d0fdcf24cecbe1fb62e4d6255d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb23d30d38c495fb0dcfffb8e27ab28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7034fe327d1f4f638b19576fac8eaf6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_989c0a35b3c44a4c872eb2f8da7f2f17",
              "IPY_MODEL_45f3e236555e47bb9c28f8363d7ba98b",
              "IPY_MODEL_ab974424e78542819bbec08adc84a05f"
            ],
            "layout": "IPY_MODEL_73ba5da47a684e46851e683b7c800677"
          }
        },
        "73ba5da47a684e46851e683b7c800677": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c0348a128542558e30b445f2f643a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e448f316927473698dba81f740f16fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12467fdae7ef484a9777a8084db2b294",
            "placeholder": "​",
            "style": "IPY_MODEL_48d9f6274e1743c68de1cf2c7ab4a81f",
            "value": "model.safetensors: 100%"
          }
        },
        "82c20d5afb4a4b2b9fda88071fc662a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87299d449bc84fd5892da0cdeb5bba8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bc814dec52f4b11b801fd8279af4a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb23d30d38c495fb0dcfffb8e27ab28",
            "placeholder": "​",
            "style": "IPY_MODEL_a35730e56c694aa2bc3b3690d6163880",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8bdbf395297141dda62dccb263348c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d79080d17254ecd994e25a88d04b405": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e55a868ed124e7ba90159ec54ce887f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bc814dec52f4b11b801fd8279af4a11",
              "IPY_MODEL_243dd4872a3040ff9d4a85d8981676e9",
              "IPY_MODEL_a0e95f47eb774c6db83b58879a896dc3"
            ],
            "layout": "IPY_MODEL_3d11755a7d234cdc8052b744332717c7"
          }
        },
        "96e8dac9fe7d4b09990b0a9b1f213b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d79080d17254ecd994e25a88d04b405",
            "max": 1246,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_189ef7fe1c6e4132a64977a432268ad5",
            "value": 1246
          }
        },
        "989c0a35b3c44a4c872eb2f8da7f2f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad9171d42364b23876b7be78442dcef",
            "placeholder": "​",
            "style": "IPY_MODEL_a55f8b8315154416a78eafd116198c73",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9aeb6df6740145d58be1cae82bc0849c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e448f316927473698dba81f740f16fb",
              "IPY_MODEL_477388a5c66d4c888cef2756d30fe06b",
              "IPY_MODEL_5a78791b81ea4d4fbf95a722b47f0392"
            ],
            "layout": "IPY_MODEL_a786ae506751465da67e052eb0565fd8"
          }
        },
        "a0e95f47eb774c6db83b58879a896dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d15d391518f24cbcb4fd92d6167bd488",
            "placeholder": "​",
            "style": "IPY_MODEL_4da58830f73b4c528493265326026b41",
            "value": " 530/530 [00:00&lt;00:00, 32.9kB/s]"
          }
        },
        "a0f164e851dc4cf38eca17d297abbfcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41682767bf44447f85ea71a37568fa39",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f55015fbdf64f14a90cac09eb0fdd7c",
            "value": 231508
          }
        },
        "a35730e56c694aa2bc3b3690d6163880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a55f8b8315154416a78eafd116198c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a786ae506751465da67e052eb0565fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab974424e78542819bbec08adc84a05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64277d0fdcf24cecbe1fb62e4d6255d6",
            "placeholder": "​",
            "style": "IPY_MODEL_257719a06099423987c3c99aa1ed081c",
            "value": " 112/112 [00:00&lt;00:00, 7.01kB/s]"
          }
        },
        "c2543e470b9347f58b0ffe58c22761e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2636da1aa30457ba66dbcd14b11ea86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c397e9778d1f4b37a9391c09db413da5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d1bcdfac274680a4ced2c1eb41df74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b455a180b6742209f58f8d5741e64fe",
            "placeholder": "​",
            "style": "IPY_MODEL_76c0348a128542558e30b445f2f643a7",
            "value": "config.json: 100%"
          }
        },
        "c914e3713eb940db9c2589857a680739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccc7ac82d1a44aa59f12361a9f77435c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3613c8602ef74f9598c083e14d7df166",
            "placeholder": "​",
            "style": "IPY_MODEL_87299d449bc84fd5892da0cdeb5bba8f",
            "value": " 232k/232k [00:00&lt;00:00, 17.6MB/s]"
          }
        },
        "d15d391518f24cbcb4fd92d6167bd488": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6603dcefe1042799e72f65f5f0de934": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2594bbaa98154941a2464fe9932ff81c",
            "placeholder": "​",
            "style": "IPY_MODEL_e69da485e3c449e08613cfbd4537da7a",
            "value": "vocab.txt: 100%"
          }
        },
        "dee83e00fc0e4c1b9bb876d9f60025ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6603dcefe1042799e72f65f5f0de934",
              "IPY_MODEL_a0f164e851dc4cf38eca17d297abbfcf",
              "IPY_MODEL_ccc7ac82d1a44aa59f12361a9f77435c"
            ],
            "layout": "IPY_MODEL_e5b4ded596004f66b15a3f17c24fd34b"
          }
        },
        "e16a064381c64f25bc49a42e6281ab4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b4ded596004f66b15a3f17c24fd34b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e67112cbfded431890a5f444c2a86376": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69da485e3c449e08613cfbd4537da7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9b29c6a6d34eb09dbf57030cd466ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb32cf4dc47c4d72b5e7590d6de61c87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba1a99f32f9492cbdafe1d5f25cedf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0f3cba5e3824566b54cd4f07f1fbd71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
